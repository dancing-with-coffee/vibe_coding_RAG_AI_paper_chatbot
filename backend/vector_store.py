import chromadb
from chromadb.config import Settings as ChromaSettings
from openai import OpenAI
from typing import List, Dict
import os
import time
from .config import settings

class VectorStore:
    def __init__(self):
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = chromadb.PersistentClient(
            path=settings.CHROMA_PERSIST_DIRECTORY,
            settings=ChromaSettings(allow_reset=True)
        )
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” - proxy ê´€ë ¨ ì„¤ì • ì œê±°
        try:
            # API í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸
            if not settings.OPENAI_API_KEY:
                raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # í™˜ê²½ ë³€ìˆ˜ì—ì„œ í”„ë¡ì‹œ ì„¤ì • ì œê±° (ìˆë‹¤ë©´)
            for proxy_var in ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy']:
                if proxy_var in os.environ:
                    del os.environ[proxy_var]
            
            self.openai_client = OpenAI(
                api_key=settings.OPENAI_API_KEY
            )
        except Exception as e:
            print(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            raise
        
        # ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
        self.collection = self.client.get_or_create_collection(
            name="research_papers",
            metadata={"description": "AI Research Papers Collection"}
        )
    
    def get_embeddings(self, texts: List[str]) -> List[List[float]]:
        """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            response = self.openai_client.embeddings.create(
                model=settings.EMBEDDING_MODEL,
                input=texts
            )
            return [embedding.embedding for embedding in response.data]
        except Exception as e:
            print(f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")
            raise
    
    def get_embeddings_batch(self, texts: List[str], batch_size: int = 50) -> List[List[float]]:
        """ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        all_embeddings = []
        total_batches = (len(texts) + batch_size - 1) // batch_size
        
        print(f"ğŸ“Š ì´ {len(texts)}ê°œ í…ìŠ¤íŠ¸ë¥¼ {total_batches}ê°œ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            batch_num = i // batch_size + 1
            
            print(f"  ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ í…ìŠ¤íŠ¸)")
            
            try:
                # ë°°ì¹˜ ì„ë² ë”© ìƒì„±
                embeddings = self.get_embeddings(batch)
                all_embeddings.extend(embeddings)
                
                # API ì œí•œì„ í”¼í•˜ê¸° ìœ„í•œ ì§§ì€ ëŒ€ê¸°
                if batch_num < total_batches:
                    time.sleep(0.5)  # 0.5ì´ˆ ëŒ€ê¸°
                    
            except Exception as e:
                print(f"  âŒ ë°°ì¹˜ {batch_num} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨í•œ ë°°ì¹˜ëŠ” ë¹ˆ ì„ë² ë”©ìœ¼ë¡œ ì±„ìš°ê¸°
                all_embeddings.extend([[0.0] * 1536 for _ in batch])  # text-embedding-ada-002ëŠ” 1536ì°¨ì›
        
        print(f"âœ… ëª¨ë“  ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ! (ì´ {len(all_embeddings)}ê°œ ì„ë² ë”©)")
        return all_embeddings
    
    def add_documents(self, documents: List[Dict]):
        """ë¬¸ì„œë“¤ì„ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€í•©ë‹ˆë‹¤."""
        if not documents:
            return
        
        texts = [doc['text'] for doc in documents]
        metadatas = [doc['metadata'] for doc in documents]
        
        try:
            # í…ìŠ¤íŠ¸ ê¸¸ì´ í™•ì¸ ë° í•„í„°ë§
            filtered_docs = []
            filtered_texts = []
            filtered_metadatas = []
            
            print(f"ğŸ“ ë¬¸ì„œ í•„í„°ë§ ì¤‘...")
            for i, (text, meta) in enumerate(zip(texts, metadatas)):
                # ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ëŠ” ì˜ë¼ë‚´ê¸° (ì•½ 8000 í† í° ì œí•œ, ë¬¸ìë¡œëŠ” ëŒ€ëµ 30000ì)
                if len(text) > 30000:
                    text = text[:30000]
                    print(f"  âš ï¸  ë¬¸ì„œ {i+1} ê¸¸ì´ ì¡°ì •: {meta['filename']}")
                
                # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ëŠ” ì œì™¸
                if len(text.strip()) < 10:
                    print(f"  â­ï¸  ë¬¸ì„œ {i+1} ê±´ë„ˆëœ€ (ë„ˆë¬´ ì§§ìŒ): {meta['filename']}")
                    continue
                
                filtered_texts.append(text)
                filtered_metadatas.append(meta)
            
            if not filtered_texts:
                print("âŒ ìœ íš¨í•œ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            print(f"âœ… {len(filtered_texts)}ê°œì˜ ìœ íš¨í•œ ë¬¸ì„œ ì„ íƒë¨")
            
            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì„ë² ë”© ìƒì„±
            print("ğŸ”„ ì„ë² ë”© ìƒì„± ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
            embeddings = self.get_embeddings_batch(filtered_texts, batch_size=50)
            
            # ê³ ìœ  ID ìƒì„±
            ids = [f"{meta['filename']}_{meta['chunk_id']}" for meta in filtered_metadatas]
            
            # ChromaDBì— ë°°ì¹˜ë¡œ ì¶”ê°€
            batch_size = 100  # ChromaDB ë°°ì¹˜ í¬ê¸°
            total_batches = (len(filtered_texts) + batch_size - 1) // batch_size
            
            print(f"ğŸ’¾ ChromaDBì— ì €ì¥ ì¤‘... (ì´ {total_batches}ê°œ ë°°ì¹˜)")
            
            for i in range(0, len(filtered_texts), batch_size):
                batch_end = min(i + batch_size, len(filtered_texts))
                batch_num = i // batch_size + 1
                
                print(f"  ë°°ì¹˜ {batch_num}/{total_batches} ì €ì¥ ì¤‘...")
                
                self.collection.add(
                    embeddings=embeddings[i:batch_end],
                    documents=filtered_texts[i:batch_end],
                    metadatas=filtered_metadatas[i:batch_end],
                    ids=ids[i:batch_end]
                )
            
            print(f"âœ… {len(filtered_texts)}ê°œ ë¬¸ì„œ ì²­í¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
        except Exception as e:
            print(f"ë¬¸ì„œ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
            raise
    
    def search_similar(self, query: str, n_results: int = 5) -> List[Dict]:
        """ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        try:
            # ì¿¼ë¦¬ê°€ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°
            if len(query) > 1000:
                query = query[:1000]
            
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self.get_embeddings([query])[0]
            
            # ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=n_results
            )
            
            # ê²°ê³¼ í¬ë§·íŒ…
            documents = []
            if results and results['documents'] and len(results['documents'][0]) > 0:
                for i in range(len(results['documents'][0])):
                    documents.append({
                        'text': results['documents'][0][i],
                        'metadata': results['metadatas'][0][i],
                        'distance': results['distances'][0][i]
                    })
            
            return documents
        except Exception as e:
            print(f"ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def reset_collection(self):
        """ì»¬ë ‰ì…˜ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        try:
            self.client.reset()
            self.collection = self.client.get_or_create_collection(
                name="research_papers",
                metadata={"description": "AI Research Papers Collection"}
            )
            print("âœ… ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}")
            raise