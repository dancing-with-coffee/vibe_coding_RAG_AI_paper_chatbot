import fitz  # PyMuPDF
import os
from typing import List, Dict
import re

class PDFProcessor:
    def __init__(self, pdf_directory: str):
        self.pdf_directory = pdf_directory
    
    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        try:
            print(f"  ğŸ“– ì²˜ë¦¬ ì¤‘: {os.path.basename(pdf_path)}")
            doc = fitz.open(pdf_path)
            text = ""
            
            for page_num, page in enumerate(doc):
                page_text = page.get_text()
                if page_text.strip():  # ë¹ˆ í˜ì´ì§€ëŠ” ê±´ë„ˆë›°ê¸°
                    text += page_text
                    
            doc.close()
            
            if not text.strip():
                print(f"  âš ï¸  ê²½ê³ : {os.path.basename(pdf_path)}ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return ""
                
            print(f"  âœ… {len(text)} ë¬¸ì ì¶”ì¶œ ì™„ë£Œ")
            return text

        except Exception as e:
            print(f"  âŒ PDF ì²˜ë¦¬ ì˜¤ë¥˜ {os.path.basename(pdf_path)}: {e}")
            return ""
    
    def clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤."""
        # ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ë³€í™˜
        text = text.replace('\n', ' ')
        text = text.replace('\r', ' ')
        
        # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ ì¤„ì´ê¸°
        text = re.sub(r'\s+', ' ', text)
        
        # íŠ¹ìˆ˜ ë¬¸ìëŠ” ìœ ì§€í•˜ë˜ ì´ìƒí•œ ë¬¸ìë§Œ ì œê±°
        text = re.sub(r'[\x00-\x1F\x7F-\x9F]', '', text)
        
        return text.strip()
    
    def chunk_text(self, text: str, chunk_size: int = 1000, overlap: int = 200) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤."""
        if not text or len(text) <= chunk_size:
            return [text] if text else []
        
        chunks = []
        sentences = self._split_into_sentences(text)
        current_chunk = ""
        
        for sentence in sentences:
            # í˜„ì¬ ì²­í¬ + ìƒˆ ë¬¸ì¥ì´ chunk_sizeë¥¼ ì´ˆê³¼í•˜ëŠ” ê²½ìš°
            if len(current_chunk) + len(sentence) > chunk_size:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                    # ì˜¤ë²„ë©ì„ ìœ„í•´ ë§ˆì§€ë§‰ ë¶€ë¶„ ìœ ì§€
                    if len(current_chunk) > overlap:
                        current_chunk = current_chunk[-overlap:] + " " + sentence
                    else:
                        current_chunk = sentence
                else:
                    # ë¬¸ì¥ í•˜ë‚˜ê°€ chunk_sizeë³´ë‹¤ ê¸´ ê²½ìš°
                    chunks.append(sentence[:chunk_size])
                    current_chunk = sentence[chunk_size:]
            else:
                current_chunk += " " + sentence if current_chunk else sentence
        
        # ë§ˆì§€ë§‰ ì²­í¬ ì¶”ê°€
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def _split_into_sentences(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• í•©ë‹ˆë‹¤."""
        # ë¬¸ì¥ ë íŒ¨í„´ (ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ ë’¤ì— ê³µë°±ì´ë‚˜ ë¬¸ì¥ ë)
        sentences = re.split(r'(?<=[.!?])\s+', text)
        return [s.strip() for s in sentences if s.strip()]
    
    def process_all_pdfs(self) -> List[Dict]:
        """ëª¨ë“  PDFë¥¼ ì²˜ë¦¬í•˜ì—¬ ì²­í¬ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤."""
        documents = []
        
        # PDF íŒŒì¼ ëª©ë¡
        pdf_files = [f for f in os.listdir(self.pdf_directory) if f.lower().endswith('.pdf')]
        
        if not pdf_files:
            print(f"âŒ {self.pdf_directory}ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return documents
        
        print(f"\nğŸ“š {len(pdf_files)}ê°œì˜ PDF íŒŒì¼ ì²˜ë¦¬ ì‹œì‘...")
        
        for idx, filename in enumerate(pdf_files, 1):
            pdf_path = os.path.join(self.pdf_directory, filename)
            print(f"\n[{idx}/{len(pdf_files)}] {filename}")
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = self.extract_text_from_pdf(pdf_path)
            if not text:
                continue
            
            # í…ìŠ¤íŠ¸ ì •ë¦¬
            cleaned_text = self.clean_text(text)
            if not cleaned_text:
                print(f"  âš ï¸  ì •ë¦¬ í›„ ë¹ˆ í…ìŠ¤íŠ¸")
                continue
            
            # ì²­í¬ ìƒì„±
            chunks = self.chunk_text(cleaned_text)
            print(f"  ğŸ“„ {len(chunks)}ê°œì˜ ì²­í¬ ìƒì„±")
            
            # ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            for i, chunk in enumerate(chunks):
                if chunk.strip():  # ë¹ˆ ì²­í¬ëŠ” ì œì™¸
                    documents.append({
                        'text': chunk,
                        'metadata': {
                            'filename': filename,
                            'chunk_id': i,
                            'total_chunks': len(chunks),
                            'source': pdf_path
                        }
                    })
        
        print(f"\nâœ… ì´ {len(documents)}ê°œì˜ ë¬¸ì„œ ì²­í¬ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return documents